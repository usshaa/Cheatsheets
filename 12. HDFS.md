HDFS (Hadoop Distributed File System) Cheatsheet ðŸŒŸ
HDFS is the primary storage system used by Hadoop applications. It is designed to store vast amounts of data across multiple machines and provide high throughput access to this data.
________________________________________
ðŸ”¹ 1. HDFS Architecture
Key Components
â€¢	NameNode: The master server that manages the file system namespace. It tracks the metadata of all the files in the system (like file-to-block mapping).
â€¢	DataNode: Worker nodes that store the actual data blocks.
â€¢	Client: Interacts with the NameNode and DataNodes to perform read/write operations.
â€¢	Secondary NameNode: Periodically merges the NameNode's namespace image with the transaction logs to prevent the NameNode's metadata from growing too large.
Block Storage
â€¢	HDFS divides files into blocks (default size: 128 MB). These blocks are distributed across multiple DataNodes.
________________________________________
ðŸ”¹ 2. HDFS Commands
1. Basic HDFS Commands
â€¢	List Files
hdfs dfs -ls /path/to/directory
â€¢	Create Directory
hdfs dfs -mkdir /path/to/directory
â€¢	Copy Local File to HDFS
hdfs dfs -copyFromLocal /local/file /hdfs/destination
â€¢	Copy File from HDFS to Local
hdfs dfs -copyToLocal /hdfs/file /local/destination
â€¢	Delete a File/Directory
hdfs dfs -rm /path/to/file_or_directory
â€¢	Display File Content
hdfs dfs -cat /path/to/file
â€¢	Check Disk Usage
hdfs dfs -du /path/to/directory
2. File Operations
â€¢	Upload Local File to HDFS
hdfs dfs -put /local/path /hdfs/directory
â€¢	Move File in HDFS
hdfs dfs -mv /old/path /new/path
â€¢	Rename File in HDFS
hdfs dfs -mv /oldfile /newfile
â€¢	Copy File from One Directory to Another
hdfs dfs -cp /source/path /destination/path
â€¢	Get File Status
hdfs dfs -stat /path/to/file
3. File Permissions
â€¢	Change Permissions
hdfs dfs -chmod 755 /path/to/file
â€¢	Change Ownership
hdfs dfs -chown user:group /path/to/file
â€¢	Check File Permissions
hdfs dfs -ls -l /path/to/file
________________________________________
ðŸ”¹ 3. HDFS High Availability (HA)
Configuring HDFS HA
â€¢	Use two NameNodes in a primary and standby configuration.
â€¢	Zookeeper is used to handle the failover between the two NameNodes.
â€¢	Edit hdfs-site.xml to configure the HA parameters like:
<property>
  <name>dfs.nameservices</name>
  <value>myCluster</value>
</property>
<property>
  <name>dfs.ha.namenodes.myCluster</name>
  <value>nn1,nn2</value>
</property>
<property>
  <name>dfs.namenode.rpc-address.myCluster.nn1</name>
  <value>namenode1.example.com:8020</value>
</property>
<property>
  <name>dfs.namenode.rpc-address.myCluster.nn2</name>
  <value>namenode2.example.com:8020</value>
</property>
<property>
  <name>dfs.ha.automatic-failover.enabled</name>
  <value>true</value>
</property>
<property>
  <name>dfs.client.failover.proxy.provider.myCluster</name>
  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
________________________________________
ðŸ”¹ 4. HDFS Configuration Files
â€¢	core-site.xml: Contains configuration for HDFS core settings.
o	fs.defaultFS: Defines the URI for accessing HDFS.
â€¢	<property>
â€¢	  <name>fs.defaultFS</name>
â€¢	  <value>hdfs://myCluster</value>
â€¢	</property>
â€¢	hdfs-site.xml: Contains configuration for HDFS-specific settings like replication factor, block size, etc.
o	dfs.replication: Number of replicas of data blocks.
â€¢	<property>
â€¢	  <name>dfs.replication</name>
â€¢	  <value>3</value>
â€¢	</property>
â€¢	mapred-site.xml: Contains configuration for MapReduce framework.
â€¢	<property>
â€¢	  <name>mapreduce.framework.name</name>
â€¢	  <value>yarn</value>
â€¢	</property>
________________________________________
ðŸ”¹ 5. HDFS Fault Tolerance
Block Replication
â€¢	HDFS replicates each block of data to multiple DataNodes to ensure data availability and fault tolerance.
â€¢	Replication Factor: Default is 3. Can be configured in hdfs-site.xml.
Check Block Replication
hdfs fsck /path/to/file -files -blocks -replication
Rebalancing HDFS
â€¢	To rebalance blocks between DataNodes:
hdfs balancer
________________________________________
ðŸ”¹ 6. HDFS Block Size
Default Block Size
â€¢	Default HDFS block size is 128 MB.
â€¢	To check block size:
hdfs dfs -stat %b /path/to/file
Change Block Size During Upload
hdfs dfs -Ddfs.blocksize=256m -put /local/file /hdfs/destination
________________________________________
ðŸ”¹ 7. HDFS Fault Tolerance with Namenode Failover
Manual Failover
â€¢	To failover from one NameNode to another:
hdfs haadmin -failover nn1 nn2
Check Namenode Health
hdfs dfsadmin -report
________________________________________
ðŸ”¹ 8. HDFS Monitoring
Check Disk Usage
hdfs dfs -du -h /path/to/directory
Check Namenode Web UI
â€¢	Access the NameNodeâ€™s web UI to view the health and status of the HDFS.
â€¢	Default: http://<namenode_host>:50070
________________________________________
ðŸ”¹ 9. HDFS Optimization
Data Compression
â€¢	Store compressed files to save disk space and reduce I/O overhead.
â€¢	Supported formats: Gzip, Snappy, BZip2, etc.
File Merging
â€¢	Large number of small files can lead to inefficiency.
â€¢	Combine smaller files into larger ones to optimize performance.
________________________________________
ðŸš€ HDFS provides scalable and reliable storage for big data applications, and understanding its commands and architecture is crucial for managing and processing large datasets in the Hadoop ecosystem.

