Apache Pig Cheatsheet ðŸŒŸ
Apache Pig is a high-level platform built on top of Hadoop for processing large datasets. It simplifies Hadoop's MapReduce complexity by using a simpler language called Pig Latin. It is mainly used for batch processing of large-scale data.
________________________________________
ðŸ”¹ 1. Pig Basics
Starting Pig
# Start Pig in local mode
pig

# Start Pig in MapReduce mode (requires Hadoop setup)
pig -x mapreduce
Loading Data
-- Load data from HDFS
data = LOAD '/path/to/data' USING PigStorage(',') AS (field1:int, field2:chararray, field3:float);

-- Load data from a local file
data = LOAD 'file:///local/path/to/data' USING PigStorage(',') AS (field1:int, field2:chararray, field3:float);
________________________________________
ðŸ”¹ 2. Data Operations
Viewing Data
-- Dump the entire dataset to the console
DUMP data;

-- Store the dataset in HDFS
STORE data INTO '/path/to/output' USING PigStorage(',');
Filtering Data
-- Filter data based on a condition
filtered_data = FILTER data BY field1 > 50;

-- Multiple conditions using AND/OR
filtered_data = FILTER data BY field1 > 50 AND field2 == 'some_value';
Projection
-- Select specific columns from the data
projected_data = FOREACH data GENERATE field1, field2;

-- Rename columns
renamed_data = FOREACH data GENERATE field1 AS id, field2 AS name;
Group By
-- Group data by a field
grouped_data = GROUP data BY field1;

-- Apply operations to the grouped data
aggregated_data = FOREACH grouped_data GENERATE group, COUNT(data);
________________________________________
ðŸ”¹ 3. Advanced Operations
Join
-- Perform a simple inner join
joined_data = JOIN data1 BY field1, data2 BY field1;

-- Perform a left outer join
joined_data = JOIN data1 BY field1 LEFT OUTER, data2 BY field1;

-- Perform a right outer join
joined_data = JOIN data1 BY field1 RIGHT OUTER, data2 BY field1;
Union
-- Combine two datasets (both must have the same schema)
union_data = UNION data1, data2;
Cogroup
-- Cogroup two datasets based on a common field
cogrouped_data = COGROUP data1 BY field1, data2 BY field2;
Ordering
-- Order data by a specific field
ordered_data = ORDER data BY field1;

-- Order in descending order
ordered_data = ORDER data BY field1 DESC;
________________________________________
ðŸ”¹ 4. Functions
Built-in Functions
-- Count the number of records
count_data = FOREACH data GENERATE COUNT(data);

-- Calculate the sum of a field
sum_data = FOREACH data GENERATE SUM(field3);

-- Get the average of a field
avg_data = FOREACH data GENERATE AVG(field3);
User-Defined Functions (UDFs)
â€¢	You can write custom UDFs in Java and register them to use in your Pig scripts.
-- Register a UDF (Java function)
REGISTER '/path/to/udf.jar';

-- Call a UDF in the Pig script
result = FOREACH data GENERATE my_udf(field1);
________________________________________
ðŸ”¹ 5. Data Types
Basic Data Types in Pig
â€¢	int: Integer values
â€¢	long: Long integer values
â€¢	float: Floating-point numbers
â€¢	double: Double precision floating-point numbers
â€¢	chararray: String values
â€¢	bytearray: Binary data
Complex Data Types
â€¢	Tuple: An ordered collection of fields (like a row in a table).
my_tuple = (field1, field2, field3);
â€¢	Bag: A collection of tuples (like a list of rows).
my_bag = { (1, 'a'), (2, 'b') };
â€¢	Map: A collection of key-value pairs.
my_map = [ 'key1'#'value1', 'key2'#'value2' ];
________________________________________
ðŸ”¹ 6. Pig Latin Operators
FOREACH
â€¢	The FOREACH operator is used to apply a transformation or computation on each record.
result = FOREACH data GENERATE field1, field2;
FILTER
â€¢	The FILTER operator is used to filter data based on conditions.
result = FILTER data BY field1 > 10;
GROUP
â€¢	The GROUP operator groups data based on a key.
grouped_data = GROUP data BY field1;
JOIN
â€¢	The JOIN operator combines two datasets based on common fields.
joined_data = JOIN data1 BY field1, data2 BY field1;
ORDER
â€¢	The ORDER operator sorts data based on a field.
ordered_data = ORDER data BY field1 DESC;
________________________________________
ðŸ”¹ 7. Data Storage Formats
Using PigStorage
-- Store data in the default PigStorage format
STORE data INTO '/output/path' USING PigStorage(',');

-- Store data in a custom delimiter format
STORE data INTO '/output/path' USING PigStorage('|');
Using Avro
-- Load data from Avro
data = LOAD '/path/to/data' USING AvroStorage();

-- Store data in Avro format
STORE data INTO '/output/path' USING AvroStorage();
Using Parquet
-- Load data from Parquet
data = LOAD '/path/to/data' USING ParquetStorage();

-- Store data in Parquet format
STORE data INTO '/output/path' USING ParquetStorage();
________________________________________
ðŸ”¹ 8. Optimizations
Execution Modes
â€¢	Local Mode: Executes the script on a single machine (for small datasets).
pig -x local
â€¢	MapReduce Mode: Executes the script on a Hadoop cluster (for large datasets).
pig -x mapreduce
Explain the Plan
â€¢	Use EXPLAIN to get the execution plan of the script.
EXPLAIN data = LOAD '/path/to/data' USING PigStorage(',');
Parallel Execution
â€¢	Use the PARALLEL keyword to specify how many reducers to use for the operation.
data = FOREACH data GENERATE field1, field2 PARALLEL 10;
________________________________________
ðŸ”¹ 9. Pig Debugging
Dumping Data
â€¢	Use DUMP to print the output to the console for debugging.
DUMP data;
Logging
â€¢	Increase the verbosity of the logs by setting the pig.log.level property.
SET pig.log.level 'debug';
________________________________________
ðŸš€ Apache Pig is great for ETL tasks and batch processing in Hadoop. These operations will help you simplify complex MapReduce tasks using Pig Latin.

