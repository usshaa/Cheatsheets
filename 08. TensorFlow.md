TensorFlow Cheatsheet ðŸŒŸ
TensorFlow is an open-source machine learning framework developed by Google for various tasks like deep learning, neural networks, and data processing. Itâ€™s one of the most widely used libraries for building and training machine learning models.
Hereâ€™s a comprehensive TensorFlow cheatsheet with key functions and examples to help you quickly implement machine learning models using TensorFlow.
________________________________________
ðŸ”¹ 1. Installation
Installing TensorFlow
pip install tensorflow
Verifying Installation
import tensorflow as tf
print(tf.__version__)
________________________________________
ðŸ”¹ 2. Tensors in TensorFlow
Creating Tensors
import tensorflow as tf

# Scalar (0-D tensor)
scalar = tf.constant(5)

# Vector (1-D tensor)
vector = tf.constant([1, 2, 3])

# Matrix (2-D tensor)
matrix = tf.constant([[1, 2], [3, 4]])

# 3D tensor
tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])

# Check tensor type and shape
print(scalar.shape)
print(vector.shape)
print(matrix.shape)
Operations on Tensors
# Addition
sum_result = tf.add(matrix, matrix)

# Matrix multiplication
product = tf.matmul(matrix, matrix)

# Element-wise multiplication
elementwise_product = tf.multiply(matrix, matrix)
Random Tensor Creation
# Random Tensor with normal distribution
rand_tensor = tf.random.normal([3, 3], mean=0, stddev=1)

# Random Tensor with uniform distribution
rand_uniform_tensor = tf.random.uniform([2, 3], minval=0, maxval=10)
________________________________________
ðŸ”¹ 3. Basic TensorFlow Operations
Reshaping Tensors
reshaped_tensor = tf.reshape(tensor_3d, [2, 4])
Slicing and Indexing
# Slicing a tensor
sliced_tensor = tensor_3d[0, :, :]

# Indexing a specific element
element = tensor_3d[1, 0, 1]
________________________________________
ðŸ”¹ 4. Building Neural Networks
Creating a Sequential Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D

# Sequential model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')  # 10 output classes for classification
])
Compiling the Model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
________________________________________
ðŸ”¹ 5. Training and Evaluating the Model
Fitting the Model
# Training the model on data
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))
Evaluating the Model
# Evaluate the model on test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")
________________________________________
ðŸ”¹ 6. Working with Datasets
Loading Dataset
from tensorflow.keras.datasets import mnist

# Load MNIST dataset
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Normalize pixel values to be between 0 and 1
X_train, X_test = X_train / 255.0, X_test / 255.0
Data Pipeline (tf.data)
# Creating a dataset pipeline for training
train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
train_dataset = train_dataset.batch(32).shuffle(buffer_size=10000)

# Iterating through dataset
for images, labels in train_dataset:
    # Train the model on each batch
    pass
________________________________________
ðŸ”¹ 7. Advanced Layers
Convolutional Layers
conv_layer = Conv2D(64, (3, 3), activation='relu', padding='same')
Recurrent Layers (RNN, LSTM)
from tensorflow.keras.layers import LSTM

# LSTM layer
lstm_layer = LSTM(64, return_sequences=True)
Dropout for Regularization
from tensorflow.keras.layers import Dropout

dropout_layer = Dropout(0.5)  # 50% of neurons are randomly dropped
________________________________________
ðŸ”¹ 8. Callbacks
EarlyStopping Callback
from tensorflow.keras.callbacks import EarlyStopping

# Stop training when accuracy stops improving
early_stopping = EarlyStopping(monitor='val_loss', patience=3)

# Add to fit() method
model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])
ModelCheckpoint Callback
from tensorflow.keras.callbacks import ModelCheckpoint

# Save the best model based on validation accuracy
checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)

# Add to fit() method
model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[checkpoint])
________________________________________
ðŸ”¹ 9. Saving and Loading Models
Saving the Model
# Save the entire model
model.save('my_model.h5')
Loading the Model
from tensorflow.keras.models import load_model

# Load a previously saved model
loaded_model = load_model('my_model.h5')
________________________________________
ðŸ”¹ 10. TensorFlow Serving
For production use, TensorFlow provides TensorFlow Serving to deploy models as web services.
# Run TensorFlow Serving via Docker
docker run -p 8501:8501 --name=tf_model_serving --mount type=bind,source=$(pwd)/my_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving
________________________________________
ðŸ”¹ 11. TensorFlow Lite (for Mobile)
Converting a Model to TensorFlow Lite
import tensorflow as tf

# Load the trained model
model = tf.keras.models.load_model('my_model.h5')

# Convert to TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the TensorFlow Lite model
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
________________________________________
ðŸ”¹ 12. TensorFlow Hub
TensorFlow Hub provides reusable model components for various tasks.
import tensorflow_hub as hub

# Load a pre-trained model from TensorFlow Hub
module_url = "https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4"
module = hub.load(module_url)
________________________________________
ðŸ”¹ 13. Optimizers
Available Optimizers
from tensorflow.keras.optimizers import Adam, SGD

# Adam Optimizer
optimizer = Adam(learning_rate=0.001)

# SGD Optimizer
optimizer_sgd = SGD(learning_rate=0.01, momentum=0.9)
________________________________________
ðŸ”¹ 14. Activation Functions
Common Activation Functions
from tensorflow.keras.layers import Dense

# ReLU (Rectified Linear Unit)
layer_relu = Dense(64, activation='relu')

# Sigmoid
layer_sigmoid = Dense(1, activation='sigmoid')

# Softmax (for multiclass classification)
layer_softmax = Dense(10, activation='softmax')
________________________________________
ðŸ”¹ 15. TensorFlow Estimators
TensorFlow Estimators are high-level API for training, evaluating, and deploying models.
from tensorflow.estimator import Estimator

# Define an estimator
model = Estimator(model_fn=model_fn, model_dir=model_dir)

# Train the estimator
model.train(input_fn=train_input_fn)

# Evaluate the estimator
eval_result = model.evaluate(input_fn=eval_input_fn)
________________________________________
ðŸ”¹ 16. Model Performance and Metrics
Using Metrics
from tensorflow.keras.metrics import Accuracy

accuracy_metric = Accuracy()

# Calculate accuracy
accuracy_metric.update_state(y_true, y_pred)
print("Accuracy:", accuracy_metric.result().numpy())
________________________________________
ðŸ”¹ 17. TensorFlow 2.x vs 1.x
TensorFlow 2.x introduced eager execution, making it easier to work with tensors directly without the need for session management as in TensorFlow 1.x.
________________________________________
ðŸ”¹ 18. Debugging with tf.debugging
Checking NaNs and Infs
tf.debugging.check_numerics(tensor, message="Tensor has NaNs or Infs")
________________________________________
TensorFlow Summary
Feature	Description
tf.constant()	Create tensors from constant values
tf.Variable()	Create a variable tensor (modifiable)
tf.keras.models.Sequential	Define a simple feed-forward model
model.fit()	Train the model on data
model.evaluate()	Evaluate model performance
model.save()	Save the model to a file
tf.data.Dataset	Efficiently handle large datasets for training
tf.keras.callbacks.EarlyStopping	Stop training early based on validation performance
tf.keras.layers	Various layers for building deep learning models
tf.keras.optimizers	Optimizers like Adam, SGD, etc.
________________________________________
ðŸš€ TensorFlow is a powerful tool for building, training, and deploying machine learning models at scale!

